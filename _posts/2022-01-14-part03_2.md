# AutoEncoder(AE)  
- 대표적인 비지도 학습 신경망 모델 중 하나이다.
- Input과 Output을 똑같이 설정하는 것이 특징으로 기본적인 구조는 다음과 같다.
![image.png](attachment:image.png)
<center> <font color=grey> [출처]https://excelsior-cjh.tistory.com/187  </font> </center>
- Hiddenlayer의 앞부분을 Encoder, 뒷부분을 Decoder라고 하며, Input 데이터에 대해 Hidden Layer로 인코딩(압축)한 후, 다시 원래 Input 데이터로 디코딩(복원)하는 개념이다.
- AE를 사용하면 Input Data를 Latent Spaceㅇ에 압축시켜 이 값을 새로운 feature로 사용할 수 있다. 즉, Feature Extraction의 일종으로 새로운 feature를 사용했을 때 기존의 feature를 사용할 때보다 성능이 좋고, Dimension을 줄일 수 있다는 장점이 있다. 여기서 성능이 좋다는 의미는 향상의 의미가 아니다.
- 자기 자신을 잘 복원할 수 있는 모델이라면 복원하는 과정 중에 있는 압축했을 때의 Feature는 Feature로서의 의미가 있을 것이다.

# Stacked AutoEncoder(SAE) 
- AE를 쌓아올린 모델로 AE의 새로운 Feature가 Feature로서의 의미가 있다면 이를 쌓아 올려 학습하면 더 좋은 학습 모델을 만들 수 있을 것이라 생각하여 나오게 된 모델이다.   


#### - 학습과정    
① Input Data로 AE1을 학습   
② ①에서 학습된 모형의 Hidden Layer를 Input으로 하여 AE2를 학습    
③ ②과정을 원하는 만큼 반복   
④ ①~③에서 학습된 Hidden Layer를 쌓아올림    
⑤ 마지막 Layer에 Softmax와 같은 Classification 기능이 있는 Output Layer를 추가    
⑥ Fine-tuning으로 전체 다층 신경망을 재학습    
※ Fine-tuning : 학습시킨 모델을 재학습시키는 개념으로 SAE가 좋은 Feature를 지니고 있는 Hidden Layer를 쌓아서 네트워크를 학습시키면 더 좋은 모델을 만들 수 있을 것이라는 생각에서 나온 것이기 때문에 여기서 ③까지의 과정처럼 미리 학습시키는 것을 `Pre-trained model`이라 하고, ⑥에서 재학습 시키는 것을 `Fine-tuning`이라 한다.

# Denoising AutoEncoder(DAE)   
- 더 강건한 모델을 만들기 위한 AE로, Input 데이터를 잘 복원하도록 학습시키는 모델이지만 Input 데이터에 약간의 noise를 추가하여 학습시킴으로서 어떤 데이터가 Input으로 오든 강건한 모델을 만들겠다는 의미이다.
- ex) 안개가 낀 상황(training)에서 운전 연습을 하면 실전(test)에 도움이 된다. -> 극한 상황에서 훈련(training)해야 실전(test)에 도움이 된다.
- Stacked Denoising AutoEncoder(SDAE)는 SAE에서 AE를 DAE로 대체한 모델이다.
